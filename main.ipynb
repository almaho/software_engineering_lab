{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48tjTShJwXo6"
   },
   "source": [
    "reading data , divide by web page, tgs of each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hm6-6bcGM_D1"
   },
   "outputs": [],
   "source": [
    "from hazm import *\n",
    "import numpy as np\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "news1 = pd.read_csv('newsrecent.csv')\n",
    "news2 = pd.read_csv('newslast.csv')\n",
    "all_news = [news1,news2]\n",
    "all_strings = []\n",
    "for news in all_news :\n",
    "#     string = ''\n",
    "    for i in range(500) :\n",
    "        string = news.loc[i]['tags']\n",
    "        all_strings.append(string)\n",
    "normalizer = Normalizer()\n",
    "n = len(all_strings) \n",
    "for i in range(n) :\n",
    "    all_strings[i] = normalizer.normalize(all_strings[i])\n",
    "    \n",
    "tags = []\n",
    "for string in all_strings :\n",
    "    word = []\n",
    "    for x in sent_tokenize(string) :    \n",
    "        for a in word_tokenize(x) :\n",
    "            word.append(a)\n",
    "    tags.append(word)\n",
    "stemmer = Stemmer()\n",
    "for i in range(n) :\n",
    "    tags[i] = [stemmer.stem(word) for word in tags[i]]\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "for i in range(n) :\n",
    "    tags[i] = [lemmatizer.lemmatize(stem) for stem in tags[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nk7Llg2_NzEl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['استانی-ورزش'],\n",
       " ['ترکیه,روسیه'],\n",
       " ['استانی-سیاسی,نماز', 'جمعه', 'مشهد,علم\\u200cالهد'],\n",
       " ['ماه', 'رمض', ',شب', 'قدر'],\n",
       " ['استانی-اجتماعی,کهگیلویه',\n",
       "  'و',\n",
       "  'بویراحمد,قتل,کهگیلویه,فرمانده',\n",
       "  'انتظامی,سید',\n",
       "  'محمد',\n",
       "  'موسو']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "o-Iro4v4N2S8"
   },
   "outputs": [],
   "source": [
    "all_strings = []\n",
    "for news in all_news :\n",
    "#     string = ''\n",
    "    for i in range(500) :\n",
    "        string = news.loc[i]['body']\n",
    "        all_strings.append(string)\n",
    "normalizer = Normalizer()\n",
    "n = len(all_strings) \n",
    "for i in range(n) :\n",
    "    all_strings[i] = normalizer.normalize(all_strings[i])\n",
    "    \n",
    "paragraphs = []\n",
    "for string in all_strings :\n",
    "    word = []\n",
    "    for x in sent_tokenize(string) :    \n",
    "        for a in word_tokenize(x) :\n",
    "            word.append(a)\n",
    "    paragraphs.append(word)\n",
    "stemmer = Stemmer()\n",
    "for i in range(n) :\n",
    "    paragraphs[i] = [stemmer.stem(word) for word in paragraphs[i]]\n",
    "lemmatizer = Lemmatizer()\n",
    "for i in range(n) :\n",
    "    paragraphs[i] = [lemmatizer.lemmatize(stem) for stem in paragraphs[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GPWLc7knOSCs"
   },
   "outputs": [],
   "source": [
    "tag_list = []\n",
    "for tag in tags :\n",
    "   tag_list.append(tag[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "59LJq4FsOZMQ"
   },
   "outputs": [],
   "source": [
    "P= []\n",
    "tags_in_para = []\n",
    "tag_len = len(tags)\n",
    "for i in range(tag_len) :\n",
    "    \n",
    "    a = [0] * tag_len \n",
    "    a2 = [0] * len(paragraphs)\n",
    "    P.append(a)\n",
    "    tags_in_para.append(a2)\n",
    "tag_index = {}\n",
    "for i in range(tag_len) :\n",
    "    tag_index[tag_list[i]] = i\n",
    "for i in range(tag_len) :\n",
    "    for j in range(tag_len) :\n",
    "        if tag_list[i] in paragraphs[j] :\n",
    "            tags_in_para[i][j] +=1\n",
    "nparr = np.array(tags_in_para)\n",
    "zarib = np.array([2, 3, 4, 5, 6, 7, 8, 9,10,9,8, 7, 6, 5, 4, 3, 2])\n",
    "for i in range(tag_len) :\n",
    "    for j in range(9,tag_len-9) :\n",
    "        if nparr[i,j] > 0 :\n",
    "            for k in range(tag_len):\n",
    "                count = 0\n",
    "                if np.sum(nparr[k, j-8:j+9]) > 0:\n",
    "                    m = np.copy(nparr[k, j-8:j+9])\n",
    "                    m *= zarib\n",
    "                    count += np.sum(m)\n",
    "                if count > 0:\n",
    "                    P[i][k] += count\n",
    "P_np  = np.array(P, np.float64)\n",
    "P1 = P_np / np.maximum(P_np.sum(axis=0),0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "a93WCyPMf9-i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GoYZy7BBgNEf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vn28DeTtS_qk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMJAbqirRLYZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhYTmdN3uEoa"
   },
   "source": [
    "Ranking tags, tags with high rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ABT-ot9ERvlj"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'coo_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfrom_numpy_matrix(P_np)\n\u001b[1;32m----> 2\u001b[0m pr \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpagerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      4\u001b[0m max_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m k\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:108\u001b[0m, in \u001b[0;36mpagerank\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpagerank\u001b[39m(\n\u001b[0;32m     10\u001b[0m     G,\n\u001b[0;32m     11\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     dangling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m ):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpagerank_scipy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersonalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdangling\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:469\u001b[0m, in \u001b[0;36mpagerank_scipy\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m    468\u001b[0m nodelist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(G)\n\u001b[1;32m--> 469\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_scipy_sparse_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m S \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    471\u001b[0m S[S \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m S[S \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\convert_matrix.py:921\u001b[0m, in \u001b[0;36mto_scipy_sparse_array\u001b[1;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[0;32m    919\u001b[0m         r \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m diag_index\n\u001b[0;32m    920\u001b[0m         c \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m diag_index\n\u001b[1;32m--> 921\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoo_array\u001b[49m((d, (r, c)), shape\u001b[38;5;241m=\u001b[39m(nlen, nlen), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m A\u001b[38;5;241m.\u001b[39masformat(\u001b[38;5;28mformat\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
     ]
    }
   ],
   "source": [
    "G = nx.from_numpy_matrix(P_np)\n",
    "pr = nx.pagerank(G, alpha = 0.9)\n",
    "k = 20\n",
    "max_values = [-1] * k\n",
    "indexes = [0] * k\n",
    "for i in pr.keys():\n",
    "    min_index = -1\n",
    "    min_value = 999\n",
    "    for j in range(k):\n",
    "        if max_values[j] <min_value:\n",
    "            min_value = max_values[j]\n",
    "            min_index = j\n",
    "    if pr[i] > min_value:\n",
    "        max_values[min_index] = pr[i]\n",
    "        indexes[min_index] = i\n",
    "tags_high = {}\n",
    "for i in range(len(indexes)):\n",
    "    index = indexes[i]\n",
    "    print(tag_list[index], ': ', max_values[i])\n",
    "    tags_high[tag_list[index]] = max_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "H0-lr2EJR0Y4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags_high' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m max_values_for_plotting \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m sub_G\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[1;32m----> 4\u001b[0m     max_values_for_plotting\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtags_high\u001b[49m[tag_list[index]])\n\u001b[0;32m      5\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indexes:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tags_high' is not defined"
     ]
    }
   ],
   "source": [
    "sub_G = G.subgraph(indexes)\n",
    "max_values_for_plotting = []\n",
    "for index in sub_G.nodes:\n",
    "    max_values_for_plotting.append(tags_high[tag_list[index]])\n",
    "mapping = {}\n",
    "for index in indexes:\n",
    "    mapping[index] = tag_list[index]\n",
    "sub_G = nx.relabel_nodes(sub_G, mapping)\n",
    "edges,weights = zip(*nx.get_edge_attributes(sub_G,'weight').items())\n",
    "weights = list(weights)\n",
    "print(sub_G.nodes)\n",
    "pos = nx.spring_layout(sub_G)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "nx.draw(sub_G, pos, edgelist=edges, edge_color=weights, width=5, edge_cmap=plt.cm.Blues, with_labels =True, node_color =max_values_for_plotting, cmap=plt.cm.Reds, font_family = 'Vazirmatn')\n",
    "plt.savefig('tags.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "5DfHw2BPhahG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yKR8ZEHoqSj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ng6JHCzdo1gr",
    "outputId": "e2b85377-61ee-4c36-8330-f1868a0cc84d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\asuscenter\\anaconda3\\lib\\site-packages (2.8.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 2.7 (from versions: none)\n",
      "ERROR: No matching distribution found for 2.7\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ASUSCenter\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install networkx  2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "-KCUAvVqXhR8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\asuscenter\\anaconda3\\lib\\site-packages (1.8.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 1.8 (from versions: none)\n",
      "ERROR: No matching distribution found for 1.8\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ASUSCenter\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install  scipy 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import *\n",
    "import numpy as np\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AIR5_0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
